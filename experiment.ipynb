{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Visualisation du modèle ConditionalFlowGenerator2d depuis Hugging Face Hub\n",
    "\n",
    "\n",
    "\n",
    " Ce notebook vous montre comment :\n",
    "\n",
    " - Télécharger le checkpoint depuis le Hub et charger le modèle.\n",
    "\n",
    " - Charger un sous-ensemble du jeu de données.\n",
    "\n",
    " - Générer des prédictions avec la méthode `sample_most_probable` (avec 100 échantillons) et visualiser les résultats.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " ## 1. Téléchargement du modèle depuis Hugging Face et visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import depuis huggingface_hub pour télécharger le checkpoint\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# On suppose que votre modèle (la classe ConditionalFlowGenerator2d) est accessible via votre repo local.\n",
    "# Par exemple, vous pouvez avoir un dossier \"models\" dans votre repository.\n",
    "from models import ConditionalFlowGenerator2d\n",
    "from dataset import load_dataset  # La fonction de chargement de dataset de votre projet\n",
    "from visu import denormalize_variable, transform_longitude  # Fonctions de visualisation/utilitaires\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Téléchargement du checkpoint depuis Hugging Face Hub\n",
    "\n",
    "\n",
    "\n",
    " Remplacez `repo_id` par l'identifiant de votre dépôt (par exemple `\"votre_nom_utilisateur/mon_modele_cf\"`)\n",
    "\n",
    " et `filename` par le nom de votre fichier de checkpoint (par exemple `\"checkpoint_epoch_10.pth\"`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4e61e074bdc4d8e87bbfaf7aba78fb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_1_16_low_reco.pth:   0%|          | 0.00/10.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint téléchargé depuis Hugging Face : /home/ensta/ensta-cesar/.cache/huggingface/hub/models--pcesar--FlowGAN/snapshots/eefda1b6521a11d548b96297391a6bf277e898f3/model_1_16_low_reco.pth\n"
     ]
    }
   ],
   "source": [
    "# Paramètres de téléchargement\n",
    "repo_id = \"pcesar/FlowGAN\"  # <-- Remplacez par votre repo Hugging Face\n",
    "filename = \"model_1_16_low_reco.pth\"              # <-- Nom de votre checkpoint\n",
    "\n",
    "# Téléchargement du fichier (il sera sauvegardé dans le cache Hugging Face)\n",
    "checkpoint_path = hf_hub_download(repo_id=repo_id, filename=filename)\n",
    "print(\"Checkpoint téléchargé depuis Hugging Face :\", checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Chargement du modèle depuis le checkpoint\n",
    "\n",
    "\n",
    "\n",
    " On définit une fonction simple pour charger le checkpoint et instancier le modèle.\n",
    "\n",
    "\n",
    "\n",
    " La fonction récupère notamment le nombre de flows (par défaut 4 s'il n'est pas précisé)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de flows dans le checkpoint : 16\n",
      "Modèle chargé et en mode évaluation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1494217/155791988.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "def load_checkpoint_cf(checkpoint_path, device):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    nb_flows = checkpoint.get(\"nb_flows\", 16)\n",
    "    print(\"Nombre de flows dans le checkpoint :\", nb_flows)\n",
    "    gen = ConditionalFlowGenerator2d(\n",
    "        context_channels=7,\n",
    "        latent_channels=3,\n",
    "        num_flows=nb_flows\n",
    "    ).to(device)\n",
    "    gen.load_state_dict(checkpoint['gen_state_dict'])\n",
    "    gen.eval()\n",
    "    return gen\n",
    "\n",
    "# Sélection de l'appareil (GPU si disponible)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = load_checkpoint_cf(checkpoint_path, device)\n",
    "print(\"Modèle chargé et en mode évaluation.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Chargement d'une partie du jeu de données pour la visualisation\n",
    "\n",
    "\n",
    "\n",
    " Ici, nous utilisons la fonction `load_dataset` de votre projet pour charger le jeu de données.\n",
    "\n",
    " Nous allons utiliser le jeu de validation.\n",
    "\n",
    "\n",
    "\n",
    " **Note :** adaptez le paramètre `root_dir` à l'emplacement de vos données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres du dataset (à ajuster selon votre configuration)\n",
    "dataset_dir = \"/home/ensta/ensta-cesar/era_5_data/\"  # Modifiez ce chemin si besoin\n",
    "datasets = load_dataset(\n",
    "    nb_file=10,\n",
    "    train_val_split=0.8,\n",
    "    year0=1979,\n",
    "    root_dir=dataset_dir,\n",
    "    normalize=True\n",
    ")\n",
    "val_dataset = datasets[\"val\"]\n",
    "\n",
    "# Utilisation d'un DataLoader pour récupérer un batch\n",
    "from torch.utils.data import DataLoader\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "# Récupérons un premier batch pour tester\n",
    "batch_data = next(iter(val_loader))\n",
    "print(\"Batch récupéré.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Préparation de l'entrée pour le modèle\n",
    "\n",
    "\n",
    "\n",
    " Dans votre pipeline, l'entrée se construit en concaténant les données d'`input`, `masks` et `coords`.\n",
    "\n",
    " On remanie ensuite les dimensions pour convenir au modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = batch_data[\"input\"].to(device)\n",
    "masks = batch_data[\"masks\"].to(device)\n",
    "lat_coord = batch_data[\"coords\"][0].unsqueeze(1).to(device)\n",
    "lon_coord = batch_data[\"coords\"][1].unsqueeze(1).to(device)\n",
    "coords = torch.cat([lat_coord, lon_coord], dim=1)\n",
    "x = torch.cat([inputs, masks, coords], dim=1)\n",
    "# Remise en forme : (batch, channels, width, height)\n",
    "x = x.permute(0, 3, 2, 1)\n",
    "print(\"Forme de l'entrée :\", x.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Génération des prédictions avec 100 échantillons\n",
    "\n",
    "\n",
    "\n",
    " Ici, nous utilisons la méthode `sample_most_probable` (votre méthode de prédiction) en spécifiant `num_samples=100`.\n",
    "\n",
    " Cela vous permet de générer la vidéo finale en considérant 100 échantillons par prédiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    fake = model.sample_most_probable(x, num_samples=100)\n",
    "\n",
    "# Réorganisation pour la visualisation : (num_samples, width, height, channels)\n",
    "fake = fake.permute(0, 3, 2, 1).cpu().numpy()\n",
    "print(\"Forme de la prédiction :\", fake.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Visualisation des prédictions\n",
    "\n",
    "\n",
    "\n",
    " Ici, nous allons visualiser le canal de température (indice 0) d'une des prédictions.\n",
    "\n",
    "\n",
    "\n",
    " Si vos données sont normalisées, nous appliquons la dénormalisation à l'aide des paramètres fournis par le dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des paramètres de normalisation depuis le dataset\n",
    "norm_params = val_dataset.get_norm_params()\n",
    "\n",
    "# Extraction du canal température (indice 0)\n",
    "temp_pred = fake[:, :, :, 0]\n",
    "# Si le dataset est normalisé, on dénormalise et on convertit de Kelvin en Celsius\n",
    "if val_dataset.normalize:\n",
    "    temp_pred = denormalize_variable(temp_pred, norm_params['2m_temperature']) - 273.15\n",
    "else:\n",
    "    temp_pred = temp_pred - 273.15\n",
    "\n",
    "# Pour la visualisation, nous transformons les longitudes si nécessaire\n",
    "temp_pred = transform_longitude(temp_pred)\n",
    "\n",
    "# Définir la grille géographique à partir des dimensions\n",
    "nlat = temp_pred.shape[1]\n",
    "nlon = temp_pred.shape[2]\n",
    "lat_vals = np.linspace(-90, 90, nlat)\n",
    "lon_vals = np.linspace(-180, 180, nlon)\n",
    "\n",
    "# Visualisation d'une prédiction (par exemple, la première des 100)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(temp_pred[0], cmap='RdBu_r', origin='lower', extent=[lon_vals.min(), lon_vals.max(), lat_vals.min(), lat_vals.max()])\n",
    "plt.title(\"Prédiction de la température (°C)\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.colorbar(label=\"Température (°C)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Remarques complémentaires\n",
    "\n",
    "\n",
    "\n",
    " - Vous pouvez adapter ce notebook pour générer des animations (vidéos) en utilisant vos fonctions de visualisation telles que `compute_animation_for_scalar` si vous souhaitez créer une vidéo finale.\n",
    "\n",
    " - Pour générer et sauvegarder une vidéo, pensez à définir un répertoire de sortie et à appeler la fonction en passant les données et paramètres (fps, année, etc.).\n",
    "\n",
    "\n",
    "\n",
    " Ce notebook constitue une base pour tester votre modèle chargé depuis Hugging Face et visualiser ses prédictions sur un sous-ensemble du jeu de données."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
